\documentclass[11pt]{article}
\usepackage{amsfonts,amsmath,amssymb,amsthm}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{url} % not crucial - just used below for the URL 
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subfig}
\usepackage{authblk}
\usepackage{verbatim} %used to comment out unnecessary contents
\usepackage{helvet}
\usepackage[colorlinks=true,pagebackref,linkcolor=magenta]{hyperref}
\usepackage[sort&compress,comma,square,numbers]{natbib}
\usepackage{fullpage,fancyhdr}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{color} %used to highlight changes
\usepackage{paralist}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}
\newcommand{\T}{^{\ensuremath{\mathsf{T}}}}           % transpose

% % DON'T change margins - should be 1 inch all around.
% \addtolength{\oddsidemargin}{-.5in}%
% \addtolength{\evensidemargin}{-.5in}%
% \addtolength{\textwidth}{1in}%
% \addtolength{\textheight}{-.3in}%
% \addtolength{\topmargin}{-.8in}%

\pagestyle{fancy}
% \oddsidemargin=-0.5in 
% \evensidemargin=-0.5in
\textwidth=6.5in 
\headwidth=6.5in
\textheight=9.0in 
\headheight=0.0pt
\topmargin=0.0in
\headsep=0.0in
\renewcommand{\headrulewidth}{0pt}

\setlength{\parindent}{0em}
\setlength{\parskip}{0.5em}

\providecommand{\sct}[1]{{\sc \texttt{#1}}}
\providecommand{\mt}[1]{\widetilde{#1}}
\providecommand{\mb}[1]{\boldsymbol{#1}}
\providecommand{\mc}[1]{\mathcal{#1}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Migraine}{\sct{Migraine}}
\newcommand{\mtg}{\sct{m2g}}

% color comments
\newcommand{\jv}[1]{{\color{red}{#1}}}
\newcommand{\cs}[1]{{\color{blue}{#1}}}

%environment
\newtheorem{thm}{Theorem}
\newtheorem{appThm}{Theorem}
\setcounter{appThm}{0}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}
\newtheorem*{defi*}{Properties}
\newtheorem{asn}{Assumption}
\newcommand*\mean[1]{\bar{#1}}
\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

\title{\bf Dependence Discovery from Multimodal Data via  Multiscale Graph Correlation}
\author[1]{Cencheng Shen\thanks{cshen@temple.edu}}
\author[2]{Carey E. Priebe\thanks{cep@jhu.edu}}
\author[3]{Mauro Maggioni\thanks{mauro.maggioni@duke.edu}}
\author[4]{Joshua T. Vogelstein\thanks{jovo@jhu.edu}}
\affil[1]{Department of Statistics, Temple University}
\affil[2]{Department of Applied Mathematics and Statistics, Johns Hopkins University}
\affil[2]{Department of Mathematics, Duke University}
\affil[4]{Department of Biomedical Engineering and Institute for Computational Medicine, Johns Hopkins University}
\maketitle
\pagestyle{empty}

\bigskip
\begin{abstract}
Understanding and discovering dependence between multiple properties or measurements of our world is a fundamental task not just in science, but also policy, commerce, and other domains. 
%In the past hundred years, people have developed many different measures of dependence that can be applied in a wide variety of settings.  
In this paper we propose a novel dependence test statistic called ``Multiscale Graph Correlation'' (MGC), having the following properties: (1) Theoretical consistency such that the testing power converges to $1$ under any dependency structure. 
%Strong theoretical support, guaranteeing rejecting independence no matter what the dependence structure is, and failing to reject when no dependence is present. 
(2) Strong empirical performance on a wide variety of low- and high-dimensional simulation settings. (3) Provides insight into the optimal local scale in which dependency is strongest. (4) On real data, detects dependence when it exists, and does not inflate the false positive rate in the absence of dependency. 
%No existing test satisfies all of these properties. 
Briefly, we combine the ideas of distance correlation testing with nearest-neighbor testing to develop MGC, and demonstrate its properties and advantages by extensive theory, simulations, and real data examples. We can therefore use this test in a variety of settings in which previous tests failed to detect signal or provide insight.
\end{abstract}

\noindent%
{\it Keywords: testing independence, distance correlation, k-nearest-neighbor, permutation test}
\vfill

\clearpage
\tableofcontents

% science report: 2500 words
% science article: 4500 words

\newpage
\spacingset{1.45}

\section{Introduction}
\label{sec:intro}
With the increasing type, size, and dimension of modern data sets, detecting dependency among multiple data sets is one of the most important and fundamental tasks in the big data age. The Pearson's correlation coefficient \cite{Pearson1895}, Spearman's and Kendall's rank correlation coefficient \cite{KendallBook}, RV coefficient \cite{RobertEscoufier1976}, Procrustes coefficient \cite{GowerProcrustesBook}, information theoretic measures \cite{Renyi1959}, and the Mantel test \cite{Mantel1967} have been the traditional tools for this task, but each has its limitations when dealing with the increasingly complex modern data sets, e.g., the Pearson's correlation coefficient and RV coefficient are mostly useful for finding linear relationship and may be zero for nonlinear dependent data sets, while mutual information performs poorly for high-dimensional data. 

Many recent methods have been proposed to identify the existence of potential relationships between data sets, including \cite{Baringhaus2004,TaskinenOjaRandles2005, GrettonEtAl2005, SzekelyRizzoBakirov2007, GrettonGyorfi2010,Reshef2011, HellerGorfine2013, Reimherr2013, SzekelyRizzo2013a, SzekelyRizzo2013b, RizzoSzekely2016}, etc. In particular, the distance correlation method from \cite{SzekelyRizzoBakirov2007, SzekelyRizzo2009, SzekelyRizzo2013a, SzekelyRizzo2014} has gained much popularity in the statistical community, due to its theoretical soundness and good numerical performance in testing independence. A similar method from the machine learning community is the kernel-based independence test, which is developed in \cite{GrettonEtAl2005, GrettonGyorfi2010, GrettonEtAl2012} and closely related to the distance-based method \cite{SejdinovicEtAl2013, RamdasEtAl2014}.

Despite current progress in the area, it remains a difficult problem to test dependency in practice; and even the best method in theory may suffer from one or more challenges underlying the modern data, such as small or huge sample size, high dimensionality, nonlinearity, noise, etc. For example, although distance correlation is consistent against all dependent alternatives for testing on Euclidean data, the sample distance correlation (dcorr) under-performs in many nonlinear or high-dimensional dependencies for finite-sample testing. The modified distance correlation (mcorr) from \cite{SzekelyRizzo2013a} adjusts the high-dimensional bias, but is still sub-optimal for many common nonlinear dependencies. In comparison, the HHG statistic developed in \cite{HellerGorfine2013} performs much better on nonlinear data of small sample size, but loses some testing power under certain noisy or high-dimensional dependencies. %Another common issue of all existing tests is their scalability for big data: depending on the underlying dependency, a given test may require too large a sample size and thus a very costly computation time to achieve a high testing power, while the test may run efficiently on a sub-sample of a large data with a low power due to the reduced sample size; so a good test that can perform well on small sub-samples from a large data is very desirable.

In a complementary literature, nearest-neighbor graphs have been used as a key computational primitive in many statistical tasks, ranging from classification and regression \cite{Stone1977} to data compression to recommender systems \cite{Sarwar2000}. 
More recently, nearest-neighbor has been an invaluable tool in unfolding nonlinear geometry in many recent development of nonlinear embedding algorithms, including Isomap \cite{TenenbaumSilvaLangford2000, SilvaTenenbaum2003}, Local Linear Embedding \cite{SaulRoweis2000, RoweisSaul2003}, and Laplacien eigenmaps \cite{BelkinNiyogi2003}, among many others; and a good choice of joint neighborhood can better unfold the nonlinearity and match data sets of multiple modality \cite{ShenVogelsteinPriebe2016}.

Most relevant to our work, a number of approaches to two-sample and dependence testing have utilized nearest-neighbor graphs \cite{David1966,Friedman1983,Schilling1986,Dumcke2014}.  These approaches have the advantage of naturally operating on any kind of data, including categorical and structured data, as well as strong theoretical guarantees.  Perhaps more importantly, they focus only on local distances, rather than global distances, enabling them to be robust to nonlinear and high-dimensional dependence structures.  However, these existing graph based tests do not provide a convenient or automatic way for choosing the appropriate neighborhood size, therefore leaving a crucial tuning parameter unspecified, and greatly impairing their practical usages and finite sample performances. 

In this paper, we propose Multiscale Graph Correlation (MGC) to better address those challenges from modern data analysis. By marrying ideas from the distance correlation literature to those from the nearest neighbor literature, and adding some of our own special sauce, we obtain a test better than those in either camp.  More specifically,  the multiscale test is able to efficiently locate the optimal scales within a family of local statistics, naturally inherits the advantages of the distance correlation such as being consistent, enjoys the properties of graph dependence structures such as better performance under nonlinear and high-dimensional dependencies, and is a better scalable method on big data. 

Those advantages make our new test statistic a great method for detecting dependency on complex simulated dependencies and real data. Indeed, in our comprehensive simulation setting, MGC is able to achieve a superior finite-sample testing power for data sets of nonlinearity, noise, and/or small sample size, comparing to existing popular methods like dcorr / mcorr / Mantel / HHG; and in the real data experiment, MGC is able to identify significant local/global dependency when testing between dependent data sets,  and does not inflate the false positive rate when the dependencies are not there in a set of brain imaging experiments. Thus, we expect MGC to find values in a wide range of applications.  To facilitate this, we provide open source MATLAB and R implementations of MGC, and incorporate into FlashR.

\section{Results}
\label{main}
\subsection{Description of Multiscale Graph Correlation}
\label{main1}
There are two key insights from the literature that we combine to develop our methodology.  First, a collection of pairwise comparisons  suffices to characterize a joint distribution \cite{Maa1996}.  Second, nonlinear manifolds can be approximated by local linear spaces.  Combining these two ideas yields our statistic,  Multiscale Graph Correlation (MGC).  

Perhaps the first realization that pairwise properties can characterize a joint distribution comes from  Karl Pearson, who created Pearson's Product-Moment Correlation \cite{Pearson1895}:
\begin{equation}
\label{generalCoef}
\frac{\sum_{i,j=1}^n a_{ij} b_{ij}}{\sqrt{\sum_{i,j=1}^n  a_{ij}^{2} \sum_{i,j=1}^n b_{ij}^{2}}}, 
\end{equation}

where $a_{ij}=x_i - \hat{E}(x)$ (where $\hat{E}(x)$ denotes the sample mean of the $x$'s'), and $b_{ij}$ is defined similarly for $y_i$.  Equation~\ref{generalCoef} can be treated as a generalized correlation coefficient, which characterizes most dependence measures since then.  For example, Spearman and Kendall's rank correlation let $a_{ij}$ equal $rank(x_i)-rank(x_j)$ and $sign(x_i-x_j)$, respectively \cite{KendallBook}; the Mantel coefficient \cite{Mantel1967} considers centered distances by letting $a_{ij}=|x_i-x_j|_{2}-\hat{E}(|x_i-x_j|_{2})$ (the expectation denotes the sample mean of all pairwise non-zero distances), which has been a popular method in biology and ecology. More recently, Szekely et al. \cite{SzekelyRizzoBakirov2007} lets $a_{ij}$ equal the doubly centered distances (so the matrix of $(a_{ij})$ has zero mean for each row and column), and show that their ``distance correlation'' statistic yielded a consistent test for dependency---a test whose power approaches $1$ as sample size approaches infinity---for any joint distribution of finite dimension and finite second moments \cite{SzekelyRizzo2009}. This is in contrast to the rank correlation or the Mantel coefficient, for which consistency does not hold against all dependent alternatives. 
Even more recently, Szekeley and Rizzo \cite{SzekelyRizzo2013a} proved that by further modifying the doubly centered distance matrix to normalize the off-diagonal and diagonal elements accordingly, the resulting test statistic is consistent even as the dimensionality of $x_{i}$ and $y_{i}$ approach infinity.  However, in all of the above cases $a_{ij}$ and $b_{ij}$ use all the data including those from points that are far from one another, such that the resulting correlation coefficient may suffer from nonlinear dependencies in its testing power.

In a separate academic lineage, manifolds have take center stage.  A manifold is a topological space that be approximated by a collection of local flat Euclidean spaces.  Although nonlinear manifold learning has been around since at least the 1950s \cite{TorgersonBook}, it rose to prominence in the early 2000s when Local Linear Embedding \cite{SaulRoweis2000} and Isomap \cite{TenenbaumSilvaLangford2000} popularized the notion that computing distances between neighboring points could enable ``unfolding'' the manifold to discover its structure.  Since then, a multitude of theoretical and empirical studies have devised different nonlinear dimensionality reduction techniques \cite{LeeVerleysen2007}, most of which are essentially generalized principal components analysis \cite{ScholkopfSmolaMuller1999}.  These approaches all require choosing the local scale parameter, a parameter of paramount importance for subsequent inference, e.g., the optimal neighborhood size. Despite of many efforts to numerically determine the parameter, to our knowledge, no approach provides a theoretically justified method for choosing the local scale; and the local scale is almost always data dependent. From a statistical point of view, the multiscale graph structure is useful for testing purposes \cite{David1966,Friedman1983,Schilling1986,Dumcke2014}, where choosing the appropriate local scale is also a difficult question.

Multiscale Graph Correlation (MGC), combines generalized correlation coefficients with multiscale graph distances.  Specifically, let $rank(a_{ij})$  be the ``rank'' of $x_i$ relative to $x_j$; that is, $rank(a_{ij})=k$ if $x_i$ is the $k^{th}$ closest point (or ``neighbor'') to $x_j$; and the minimal rank is used for ties.  Then for any test statistic that can be expressed by the general correlation coefficient in Equation~\ref{generalCoef}, we define its \emph{local} variants by
\begin{equation}
\label{localCoef}
g_{kl}=\frac{\sum_{i,j=1}^n a_{ij}^k b_{ij}^l}{\sqrt{\sum_{i,j=1}^n  a_{ij}^{k} a_{ij}^{k} \sum_{i,j=1}^n b_{ij}^{l} b_{ij}^{l}}},
\end{equation}
for each $k,l=1,\ldots,n$, where
\begin{equation}
\label{localCoef2}
    a_{ij}^k=
    \begin{cases}
      a_{ij}, & \text{if } 0 \leq rank(a_{ij}) < k, \\
      0, & \text{otherwise};
    \end{cases} \qquad \qquad
    b_{ij}^l=
    \begin{cases}
      b_{ij}, & \text{if } 0 \leq rank(b_{ij}) < l, \\
      0, & \text{otherwise}.
    \end{cases}
\end{equation}
Note that if there are repeating points in the data, some generalized correlation coefficients like mcorr may need separate treatments for the rank $0$ case, which is discussed in appendix section~\ref{appen:methods}.

\cs{Since the repeating points is no longer a major issue as we no longer use re-sampling with replacement, I moved the tie problems to a short paragraph in the appendix mcorr section, so the main paper looks clearer.}

When $a_{ij}$ is the Pearson's correlation, $g_{kl}$ is a local Pearson's correlation;
When $a_{ij}$ is the Spearman or Kendall's rank correlation, $g_{kl}$ is a local rank correlation;
when $a_{ij}$ is the centered distances, $g_{kl}$ is the local Mantel correlation;
when $a_{ij}$ is the doubly centered distances, $g_{kl}$ is a local distance correlation;
when $a_{ij}$ is the doubly centered distances modified for the high-dimensional bias, $g_{kl}$ is a local modified distance correlation, etc.

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{../Figures/FigA}
\caption{
Flowchart of Global to Local Distance Correlation: Column 1: $(X,Y)$ have a quadratic relationship with some noise. Column 2: the distance matrix heat maps for $X$ and $Y$. Column 3: Doubly-centered distance matrix heat maps, i.e., $\{a_{ij}\}$ and $\{b_{ij}\}$, which can be used to calculate the global distance correlation. Column 4: Local doubly-centered distance matrix heat maps, where an optimal scale is already estimated with all non-local entries set to $0$ and shaded white. Column 5: The entry-wise product heat map of column 4. Summing over all entries in Column 5 yields the un-normalized MGC statistic (for dcorr); divide it by the product of the Frobenius norm of each matrix in Column 4 yields the MGC statistic. }
\label{fig:A}
\end{figure}

In the family of local statistics $\{g_{kl}\}$, the optimal local test statistic (optimal with respect to the testing power) is dubbed the multiscale graph correlation. Clearly the optimal scale exists, is distribution dependent, and may not be unique. But different from a manifold learning task, the optimal scale within the dependence testing framework can be efficiently estimated: if the underlying joint distribution is known, the true optimal scale can be directly derived by maximizing the testing powers among all local tests; if there is only one pair of observations with unknown underlying model, the optimal scale is sequentially approximated and verified based on local p-values from the permutation test. 

Once the optimal scale is determined, the local statistic at the estimated optimal scale is used as the MGC statistic. For a pair of given data, if the MGC p-value (i.e., the p-value of the optimal local test) from the permutation test is sufficiently low, say less than $0.05$, then we declare significant dependency. A flowchart on how to calculate the MGC statistic is provided in figure~\ref{fig:A}, and more details on optimal scale estimation and MGC evaluation are provided in appendix section~\ref{appen:tests}.

MGC can be implemented by any global statistics in the form of the generalized correlation coefficient. By the optimal scale estimation, MGC is theoretically no worse than the global counterpart, and usually enjoys better testing powers under high-dimensional and/or nonlinear dependencies. Different MGC implementations may vary slightly in performance, and some may do particularly well under certain dependency, depending on the properties of the respective global statistic. For example, since mcorr performs the best under high-dimensional dependencies, MGC implemented by mcorr also empirically performs better than other implementations of MGC under high-dimensional linear dependencies. 

Below we demonstrate that our local modification yields tests that preserve consistency regardless of the functional dependency and dimensionality, improve the testing powers under nonlinear and high-dimensional dependencies both in theory and in simulations, as while as being the most superior method for simulations and real data experiments.


\subsection{Theoretical Consistency and Efficiency for Any Dependence Structure}
\label{main2}
In this section we present the theoretical properties of multiscale graph correlation. The proofs are provided in the appendix section~\ref{appen:proofs}. 

The testing framework is as follows: suppose two data sets $X=[x_{1},\cdots, x_{n}] \in \Real^{d_{x} \times n}$ and $Y=[y_{1},\cdots, y_{n}] \in \Real^{d_{y} \times n}$ are given, where $n$ is the sample size, $d_{x}$ and $d_{y}$ are the dimensions for each data set. Under the classical hypothesis testing framework, $x_{i}, i=1,\ldots,n$ are assumed identically independently distributed (iid) as $\mb{x} \sim f_{x}$, where $f_{x}$ denotes the distribution of $\mb{x}$; similarly $y_{i}$ are independent realizations of $\mb{y} \sim f_{y}$. Then the null and the alternative hypothesis for testing independence are
\begin{align*}
& H_{0}: f_{xy}=f_{x}f_{y},\\
& H_{A}: f_{xy} \neq f_{x}f_{y},
\end{align*}
where $f_{xy}$ denotes the joint distribution of $(\mb{x},\mb{y}) \in \Real^{d_{x} + d_{y}}$. 

A consistent test statistic has power $1$ asymptotically, e.g., the test statistic $g_{nn}$ under the alternative should be asymptotically larger than $g_{nn}$ under the null. Denote the type 1 error level as $\alpha$, the testing power of MGC as $\beta_{\alpha}(g)$, and the power of the respective global test as $\beta_{\alpha}(g_{nn})$. Assuming the optimal scale is estimated by the testing power, we have the following theorem regarding the consistency of MGC:
\begin{thm}
\label{thm1}
Suppose for given $f_{xy}$ and $\alpha$, $\beta_{\alpha}(g_{nn}) \rightarrow 1$ as $n \rightarrow \infty$ for given $f_{xy}$ and $\alpha$, then $\beta_{\alpha}(g) \rightarrow 1$ as well.

Therefore, multiscale graph correlation is consistent against all dependent alternatives of finite second moments, when it is implemented by distance correlation or modified distance correlation.
\end{thm}

Note that the consistency of MGC in Theorem~\ref{thm1} is not applicable to MGC$\{$Mantel$\}$, since the global Mantel coefficient is not consistent against all dependent alternatives \cite{JosseHolmes2013}; but throughout our numerical experiments, MGC$\{$Mantel$\}$ has similar performance as MGC$\{$dcorr$\}$, and can be more advantageous under certain dependencies.

In addition to theoretical consistency, MGC also is computationally efficient. Computing the distance between all points takes $O(n^2)$, sorting the distance matrices within each column takes $O(n^2\log(n))$, computing $\{g_{kl}\}$ at one given scale or all scales can be implemented in $O(n^2)$, which allows the optimal scale of MGC to be quickly estimated. Therefore MGC is comparable in running time complexity to the global statistics, e.g., dcorr and mcorr take $O(n^2)$, while rank correlation and HHG take $O(n^2\log(n))$ due to sorting. More details on the running time analysis is provided in appendix section~\ref{appen:tests}.

\subsection{Low Dimensional Simulation Experiments}
\label{numer1}
In this section and the next, we show the numerical advantage of multiscale graph correlation (using dcorr / mcorr / Mantel) via the empirical testing powers. The detailed evaluation procedure is provided in appendix section~\ref{appen:tests}, and the benchmarks are dcorr, mcorr, Mantel, and HHG.

In total $20$ different distributions of $f_{xy}$ are considered, taken from existing literature \cite{SzekelyRizzoBakirov2007, SimonTibshirani2012, GorfineHellerHeller2012, HellerGorfine2013}: they consist of various linear and close to linear dependencies (type 1-5), polynomial-based nonlinear relationships (type 6-12), trigonometry-based nonlinear dependencies (type 13-17), two uncorrelated dependencies (type 18-19), and an independent relationship (type 20) to show that MGC does not detect additional signals in the absence of dependency. The exact simulation distributions are given in appendix section~\ref{appen:function}, with a visualization of each dependency shown in supplementary figure~\ref{fig0}.

We first experiment on a dimension $1$ scenario at $d_{x}=d_{y}=1$. To observe how fast the testing power of each method converges to $1$ under different dependencies, the testing powers are calculated with respect to the increasing sample size $n$ from $5$ to $100$. The empirical powers based on $r=10$,$000$ Monte-Carlo replicates are plotted in figure~\ref{fig:1D} at type $1$ error level $\alpha=0.05$. Note that we use $2$,$000$ additional MC replicates to generate repeating simulating samples and estimate the optimal scale of MGC; and the MGC optimal scales for dcorr / mcorr / Mantel are estimated individually.

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{../Figures/Fig1}
\caption{
Power of different methods on 20 different one-dimensional simulation settings, estimated by the empirical distributions of the test statistics under the null and the alternative on the basis of $10$,$000$ Monte-Carlo replicates.
Each panel shows empirical testing power on the absicca, and sample size on the ordinate.
MGC empirically achieves similar or better power than the previous state of the art approaches for nearly all sample sizes on most problems.}
\label{fig:1D}
\end{figure}

For the dimension $1$ scenario, MGC$\{$dcorr$\}$/$\{$mcorr$\}$/$\{$Mantel$\}$ either equals or is better than its corresponding global test. For dependencies that are close to linear (type 1-5), MGC usually yields similar testing powers as dcorr and mcorr, which are slightly better than HHG and Mantel; for the remaining nonlinear dependencies (type 6-19), HHG is the best among all global statistics, yet MGC is able to achieve similar or even better performance than HHG in almost all cases except type $15$. 

Note that for all distributions other than the independent clouds, the empirical powers eventually increase to $1$ as the sample size increases, implying that all methods are consistent except the Mantel test, whose powers stay low in many nonlinear dependencies; and for the independent clouds, the empirical power of MGC is approximately at the type $1$ error level, so no false signal is detected once an optimal scale is determined. 

To better summarize the overall performance in the dimension $1$ simulations, we use the performance profiles \cite{DolanMore2002}, which provides an intuitive way for directly comparing a set of algorithms on a set of problems.  Briefly, each curve (profile) shows the relative performance of a given algorithm as a function of how far from the best algorithm it performed; therefore, higher curves and larger area under curve are better; a more detailed description is in appendix section~\ref{appen:profiles}. For the dimension $1$ scenario, we fix the sample size by a power threshold, and draw the corresponding performance profiles of all methods in figure~\ref{fig:pp}(a). To compare the performance profiles of each method with respect to different threshold choices, the area under curve of the performance profiles against the power threshold is provided in figure~\ref{fig:pp}(b).
\begin{figure}[htbp]
\subfloat[]{
\includegraphics[width=0.5\textwidth]{../Figures/Fig3}
}
\hfil
\subfloat[]{
\includegraphics[width=0.5\textwidth]{../Figures/Fig4}
}
\hfil
\subfloat[]{
\includegraphics[width=0.5\textwidth]{../Figures/Fig7}
}
\hfil
\subfloat[]{
\includegraphics[width=0.5\textwidth]{../Figures/Fig8}
}
\caption{Quantitative comparisons of the power of the various algorithms across all simulations into a single number.  
(a) Performance profile plots comparing the different algorithms on all 1-dimensional problems at the first sample size $n$ of any testing power to exceed the power threshold 0.8. The legend provides the Area-Under-the-Curve (AUC) for each method; larger is better.
(b) AUC for each method sweeping over all different power thresholds, the higher the better.
(c) Same as (a) but for the high-dimensional simulations, at the last dimension of any testing power that is above the power threshold 0.5.
(d) Same as (b) but for the high-dimensional simulations.
It is clear that MGC outperforms the previous state of the art, regardless of function, sample size, and dimensionality.}
\label{fig:pp}
\end{figure}

MGC is clearly more reliable than all global tests in the dimension $1$ scenario from figure~\ref{fig:pp}(a)(b). HHG is slightly better than dcorr / mcorr in the performance profiles, because there are more nonlinear simulations than linear in the $20$ dependencies, and HHG has a larger advantage for nonlinear dependency than its disadvantage in linear dependency; the global Mantel test has the lowest performance profile, but MGC$\{$Mantel$\}$ turns out to perform the best due to its advantage in type 11-13. 

%Note that the powers and performance profiles of MGC$\{$dcorr$\}$ and MGC$\{$Mantel$\}$ on the low dimensional simulations are provided in the appendix Section~\ref{appen:figure}, which perform slightly differently from MGC$\{$mcorr$\}$, but give the same interpretations regarding their advantages over all global statistics.


\subsection{High Dimensional Simulation Experiments}
\label{numer2}
In this section we consider the same $20$ distributions and the same testing procedures as in section~\ref{numer1}, but under an increasing dimensional setting. For each dependency type, the testing powers are calculated against increasing $d_{x}$, with $d_{y}$ equals $d_{x}$ or $1$ depending on the particular distribution and the sample size fixed at $n=100$.

The empirical testing powers are again based on $r=10$,$000$ Monte-Carlo replicates at $\alpha=0.05$, and the optimal scale of MGC is estimated by $2$,$000$ additional MC replicates. The powers are shown in figure~\ref{fig:nD} against $d_{x}$, and the performance profiles are provided in figure~\ref{fig:pp}(c)(d): figure~\ref{fig:pp}(c) draws the performance profiles of all methods at a fixed dimension determined by a power threshold; and figure~\ref{fig:pp}(d) plots the area under curve of the performance profiles against the power threshold.

Like the dimension $1$ scenario, each MGC test either equals or is better than its corresponding global test in the increasing dimension scenario. In particular, for close to linear dependencies from type 1-5, MGC$\{$mcorr$\}$ and global mcorr are the best, whose powers deteriorate slower than the others; and for the remaining nonlinear dependencies (other than type 15), MGC has a significant advantage over the benchmarks due to its capability to better handle nonlinearity and high-dimensionality at the same time. The performance profiles of MGC in figure~\ref{fig:pp}(c)(d) clearly reflect its superiority.

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{../Figures/Fig5}
\caption{Power of different methods on 20 different simulation settings, for dimensionality ranging from 1 to 1000.  Details as in figure~\ref{fig:1D}.
Again, our method empirically achieves as high or higher power than the previous state of the art approaches for nearly all sample sizes on nearly all problems and dimensions.
}
\label{fig:nD}
\end{figure}

\subsection{Discovery of Dependency Across Scales}
\label{main3}

Figure~\ref{figSim6} illustrates how the powers of local statistics $\{g_{kl}\}$ change with respect to increasing neighborhood $k$ and $l$, for the high-dimension simulations (the low dimension case is included in appendix). They are plotted at a fixed sample size and a fixed dimension by the same thresholds as the performance profiles figures in figure~\ref{fig:pp}(a)(c). 

The powers of local tests can be very close for nearby scales, since the local statistics are strongly correlated with each other. In fact, there always exists some optimal scales $(k^{*},l^{*})$ whose entire row or column scales are equally significant for most of them. For example, for type 6 quadratic, $(k^{*},l^{*})=(n/4, n)$ is one such optimal scale such that $(k,l^{*})$ are equally significant for most $k \in (2,n)$; for type 16 sine period, $(k^{*},l^{*})=(2, n)$ is an optimal scale such that $(k^{*},l)$ are equally significant for most $l \in (2,n)$, etc. This is a key observation that we will use to sequentially approximate and verify the optimal scale in section~\ref{numer3} and appendix section~\ref{appen:tests}, when there is only one pair of data with unknown model.

For dependencies that are close to linear (type 1-5), the best neighborhood choice is approximately at the largest scale, i.e., $k=l=n$. But for all other nonlinear dependencies (type 6-19), MGC almost always chooses a smaller scale, which is data dependent; and similar nonlinear dependencies yield similar optimal scales. For example, type 6 and type 7 are both polynomials of degree 2 with different coefficients, and the optimal scales are very similar to each other; type 16 and 17 are the same trigonometry function with different periods, and they share almost the same optimal scales; so are circle and eclipse, and square and diamond.

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{../Figures/Fig6}
\caption{Testing Power Heat map of Local Statistics with respect to Neighborhood Choices for High Dimension.
For each of the 20 panels, the abscissa denotes the number of neighbors for $X$ (the scale increases from left to right), and the ordinate denotes the number of neighbors for $Y$ (the scale increases from bottom to top).  Each different simulation yields a different surface, highlighting the importance of understanding local scale in terms of understanding the data.}
\label{figSim6}
\end{figure}

To characterize the above behaviors, in the following theorems we prove that the testing power of MGC by the permutation test equals the testing power of the global test statistic under linear dependency, i.e., the largest scale $(n,n)$ is always an optimal scale of MGC. But under certain nonlinear dependency, $(n,n)$ may no longer be an optimal scale such that MGC enjoys a better finite-sample testing power than the corresponding global statistic. 

\begin{thm}
\label{thm2}
Suppose $\mb{y}=c\mb{x}$ for a non-zero scalar $c$. Then for any $n$ and $\alpha$ it always holds that
\begin{equation}
\beta_{\alpha}(g) = \beta_{\alpha}(g_{nn}).
\end{equation}

Thus multiscale graph correlation is equivalent to the global correlation coefficient under linear dependency.
\end{thm}

\begin{thm}
\label{thm3}
There exists $f_{xy}$, $n$ and $\alpha$ such that 
\begin{equation}
\beta_{\alpha}(g) > \beta_{\alpha}(g_{nn}).
\end{equation}

Thus multiscale graph correlation can be better than its global correlation coefficient under certain nonlinear dependency.
\end{thm}
Note that Theorem~\ref{thm2} and Theorem~\ref{thm3} hold for MGC implemented by any of dcorr / mcorr / Mantel.

The proof of Theorem~\ref{thm3} is a constructive one, as it shows that local distances and local statistics outperform global ones even for the most modest nonlinear functions, such as a quadratic.  Because any function can be approximated by a polynomial expansion \cite{RudinBook}, the proof of Theorem~\ref{thm3} suggests that MGC is likely to outperform the corresponding global statistic on a wide variety of nonlinear functions, which is indeed the case throughout the numerical simulations.


\subsection{Robustness against Outliers}
\label{main4}
The global correlation coefficient may suffer from outliers in the data, but MGC is robust against outliers by choosing the appropriate scale.

Let us consider a mixture model: suppose the joint distribution satisfies $f_{xy}=p f_{1}+(1-p) f_{2}$, where $f_{1}=1$ if and only if $-1<x=y<1$, $f_{2}=Normal_{x}(5,1) \times Normal_{y}(-5,1)$, and $p$ is the prior probability. Namely $x=y$ with probability $p$, otherwise independently normally distributed. Given $p$, the simulating sample pairs $(X,Y)$ at $n=100$ can be repeatedly generated to estimate the testing powers at $\alpha=0.05$. \jv{can you explicitly write the mixture model, i.e., F = F1 + F2, and specify both F1 and F2? this will make it more clearly a mixture model, and in particular, a mixture of a linear function and an independent function.}
\cs{isn't the above formulation already in the form of F=p F1+(1-p)F2, where $p$ is the mixture weight, and $\mb{u}$ is the linear function common in both models?} \jv{no, it can be interpretted in that way, but it is obviously not in that form.  i'm saying write $X,Y) \sim F$, where $F= p F1 + (1-p) F2$, and then define explicitly F1 and F2. is that more clear?}
\cs{ok, tried again above by $f_{xy}$}

For sample data generated under the mixture model, there are $pn$ observations in $X$ that are exactly the same as the corresponding observations in $Y$; and the remaining observations in $X$ are outliers, which are independent from the corresponding observations in $Y$. One such sample pair $(X,Y)$ at $p=0.5$ is plotted in figure~\ref{figSim3}(a), and the testing powers of all local tests by mcorr are shown in figure~\ref{figSim3}(b)(c)(d) for $p=0.3$,$0.5$,$0.7$ respectively, using the same evaluation procedure as the simulations in section~\ref{numer1}.

The local mcorr at the optimal scale is clearly much better than global mcorr. Furthermore, the optimal scale $(k^{*},l^{*})$ is directly related to the probability $p$, and at least one of $k^{*}$ and $l^{*}$ should be bounded above by $\min(pn,(1-p)n)$ to achieve optimal testing powers. Therefore, MGC is able to automatically separate the independent outliers from the dependent observations in testing, which makes it robust against outliers.

The same robustness still holds as the dimension or sample size increases, or the underlying dependency changes from linear to other types. Such robustness makes MGC more advantageous in practice. 

\begin{figure}[htbp]
\subfloat[]{
\includegraphics[width=0.5\textwidth]{../Figures/FigOut0}
}
\hfil
\subfloat[]{
\includegraphics[width=0.5\textwidth]{../Figures/FigOut1}
}
\hfil
\subfloat[]{
\includegraphics[width=0.5\textwidth]{../Figures/FigOut2}
}
\hfil
\subfloat[]{
\includegraphics[width=0.5\textwidth]{../Figures/FigOut3}
}
\caption{Testing Power Heat map of Local Statistics with respect to Neighborhood Choices under the Outlier Model.
(a) Scatter Plot of sample $(X,Y)$ under the outlier model with probability $p=0.5$
(b) Testing Power of All Local Tests under the outlier model with probability $p=0.3$.
(c) Same as (b) with $p=0.5$.
(d) Same as (b) with $p=0.7$.
}
\label{figSim3}
\end{figure}

\subsection{Real Data Experiment}
\label{numer3}
Here MGC is applied to test independence between real data sets. Among the three MGC implementations, we concentrate on MGC$\{$mcorr$\}$ as the other two implementations yield similar performance during the experiments. As there is no known model for the given data, the optimal scale of MGC is sequentially approximated by first locating some optimal indices $k^{*}$ or $l^{*}$ that are sufficiently powerful (i.e., has many significant p-values on that row or column), followed by searching the other optimal index by the smallest p-value. Then the MGC p-value equals the p-value at the estimated optimal scale. More details and discussions regarding the optimal scale estimation on data of unknown model are in appendix section~\ref{appen:tests}.

\subsubsection{Brain Shape vs. Disease}

The first experiment is to test dependency between the brain hippocampus shape and major depressive disorder. There are $n=114$ subjects, and the brain images of each person are obtained by high resolution MRI scans on the hippocampus for both the left brain and the right brain. A categorical vector containing the disorder information is also available, including clinically depressed subject, high-risk subject, and non-affected subject. There has been evidences that relate major depressive disorder to the hippocampus shape in \cite{ParkEtAl2011} and \cite{PosenerEtAl2003}, and we would like to test the significance of such relationship in the raw data. 

To apply the methods, the respective data sets need to be transformed into distance matrices. For the brain data, two dissimilarity matrices representing the left and right hippocampus data are already obtained based on landmark matching (see \cite{ParkEtAl2011} for more details on data processing). For the disorder information vector,
its dissimilarity matrix is formed by the Euclidean distances of the vector, followed by adding $1$ to all off-diagonal entries such that only the diagonals are $0$.

Two hypothesis tests are considered: testing dependency between the left brain and major depressive disorder, and testing dependency between the right brain and major depressive disorder. Based on $r=10$,$000$ random permutations, the resulting p-values are reported in the first two rows of Table~\ref{table1}. For testing between the left brain and the disorder, MGC / HHG / Mantel yield significant p-values with dcorr / mcorr being slightly higher than significance; for testing between the right brain and the disorder, only MGC yields significant p-value, and all global tests have p-values higher than significance. 

The p-value curves of the local tests are provided in figure~\ref{figReal}(a) with respect to the choice of $k$ at $l=4$. We only show the curves at $l=4$ because the p-values of local tests at a fixed $k$ are the same throughout $l \in [4,114]$ (as the largest rank is $3$ for the disorder dissimilarity matrix), and the scales at $l<4$ are neither optimal nor yield significant p-values. We can clearly identify many common local scales between the two curves that yield significant p-values, which implies a local dependency structure and is the reason that MGC can successfully identify the signals. %The estimated optimal scales are $k^{*}=65$ and $k^{*}=64$ (and $l^{*}$ can be any number larger than $3$) respectively for left brain and right brain vs disease, based on $2,000$ MC replicates. As the optimal scales are very similar, it indicates the left brain and the right brain may have similar dependence structures when testing against the disease.


\begin{table*}[!t]
\footnotesize
\renewcommand{\arraystretch}{0.5}
\centering
{\begin{tabular}{|c||c|c|c|c|c|c|c|}
\hline
Testing Method & MGC & dcorr & mcorr & Mantel & HHG \\
\hline
Left Brain vs Disorder  & $0.0173$ & $0.0806$ & $0.0820$ & $0.0399$ & $0.0368$ \\
\hline
Right Brain vs Disorder & $0.0051$ & $0.1033$ & $0.1105$  & $0.0826$ & $0.0809$\\
\hline
\Migraine~vs CCI & $0.0077$ & $0.0081$ & $0.0099$  & $0.0095$ & $0.0316$\\
\hline
\mtg~vs CCI & $1$ & $0.0698$ & $0.0502$  & $0.3040$ & $0.6578$\\
\hline
\end{tabular}
\caption{The Empirical P-Values in the Permutation Test}
\label{table1}
}
\end{table*}

\begin{figure}[htbp]
\centering
\subfloat[]{
\includegraphics[width=0.48\textwidth]{../Figures/FigReal1}
}
\hfil
\centering
\subfloat[]{
\includegraphics[width=0.48\textwidth]{../Figures/FigReal2}
}
\hfil
\centering
\subfloat[]{
\includegraphics[width=0.48\textwidth]{../Figures/FigReal3}
}
\hfil
\centering
\subfloat[]{
\includegraphics[width=0.48\textwidth]{../Figures/FigReal4}
}
\caption{
(a) Local Tests P-value Curves with respect to $k$ at $l=4$ for brain vs disease. 
(b) False positive rates for brain vs noise throughout $24$ different data sets. Red cross is global mcorr, blue circle is MGC.
(c) Local Tests P-value Heat map with respect to $k$ and $l$ for brain \Migraine~vs disease. 
(d) Local Tests P-value Heat map with respect to $k$ and $l$ for brain \mtg~vs disease. }
\label{figReal}
\end{figure}

\subsubsection{Brain Structural Network vs. Creativity}

Next we experiment on \Migraine~vs CCI and \mtg~vs CCI. More specifically, we estimated brain graphs from diffusion MRI data using two different pipelines, one called \Migraine, and the other called \mtg.  The question we have is whether brain graphs are independent of creativity.  Because we cannot directly measure brain graphs, we must estimate them from the data.  Currently, the jury is out on which estimation procedure is best.  Therefore, we tried both to determine which worked better for this particular task.

Using the same testing procedure as the previous experiment, the resulting p-values for \Migraine~vs CCI and \mtg~vs CCI are reported in the last two rows of Table~\ref{table1}. The dependency between \Migraine~and CCI are very significant, with all methods returning significant p-values. But there is a loss of dependency between \mtg~and CCI, as neither the global methods nor MGC return significant p-values. 

We visualize the local p-value heat maps in figure~\ref{figReal}(c)(d). It is clear that there exists many local scales with significant p-values for \Migraine~vs CCI, which is no longer the case for \mtg~vs CCI. Although there exists a few scales producing p-values around $0.05$ in figure~\ref{figReal}(d), the signals are not strong enough for those few scales to be considered optimal by our algorithm. 

\jv{i don't understand this comment.  optimal scale is the one with the smallest p-value? or estimated higher power? what is the smaller p-value?}
\cs{optimal scale is the one with the highest power. The optimal scale that has the highest power means it is the most reliable scale for testing: more likely to reject ind hypothesis if and only if dependent. For example, a scale that has a smaller p-value may also has a low power, which means the p-value is not so reliable.}
\jv{but how can none be the optimal scale? oh, you mean that for the scales with p less than .05, the power is not as large as other powers? if you mean something like that, please clarify.}
\cs{yes; and under the new estimation method, there is no $k$ or $l$ with many significant p-values.}
If we test dependency between \Migraine~vs \mtg, all p-values become $0$, indicating a strong dependency. 

Therefore in this exploration task, \Migraine~is a better brain graph estimator than \mtg: although they are strongly dependent with each other, \Migraine~is more related to CCI than \mtg, because \mtg~is a transformation of \Migraine~without consideration of CCI. Our MGC statistic identifies the better representation of the two, reveals the local dependency loss from the p-value heat maps, and does not identify false signals. Therefore MGC can be used to find the most relevant representation / variable and provide valuable insights into the structural difference.

\subsubsection{Brain Activity vs. Noise}

In the last experiment, MGC is applied to test independence between brain voxel activities and non-existent stimulus similar to \cite{EklundKnutsson2012}, by using $24$ resting state fMRI data sets from the Neuroimaging Informatics Tools and Resources Clearinghouse (NITRC) 1000 functional connectomes project \url{http://fcon_1000.projects.nitrc.org/}. Take one data set BNU1 for example: the resting state data contains $200$ regions of interest for $200$ timestep for $50$ persons; and there are 
two resting state data for the same person. We used CPAC to estimate regional time-series, in particular, using the sequence of pre-processing decisions determined to optimize discriminability (unpublished).

For each brain region, denote $x_{\cdot t}$ as the observation vector at timestep $t$ for all persons, then the distance matrix with respect to time is calculated by $dist(s,t)=\|x_{\cdot s}-x_{\cdot t}\|$. We generate an independent stimulus by sampling from a standard normal at each time step, whose Euclidean distance matrix can be easily calculated. Using the two distance matrices, the dependency between each brain region and the stimulus can be tested by our methods. The p-value of each method is calculated using $1000$ permutations, and each brain region is declared significant when the p-value is less than $\alpha=0.05$. Note that the distance matrices at different brain regions are distinct, but the stimulus is the same for all brain regions during the same experiment.

For each data set, the above testing is carried out for each brain region with the false positive rate of MGC and mcorr shown in figure~\ref{figReal}(b). Because the stimulus is in fact independent from the brain activities, the false positive rate should be close to $\alpha=0.05$ for each data set. Clearly MGC does not inflate the false positive rate, and the mean/standard deviation for MGC is $0.0602 \pm 0.0515$, and $0.0444 \pm 0.0356$ / $0.0626 \pm 0.0491$ / $0.0594 \pm 0.0559$ / $0.0552 \pm 0.0310$ for dcorr/mcorr/Mantel/HHG respectively. This is in contrast to many other methods compared in the literature \cite{EklundKnutsson2012}.

\jv{let's move the table to the appendix, and add just a jittered scatter plot of MGC false positive rate, to include in the other real data figure?}
\cs{done; let me know if you want a better looking scatter plot}
\jv{i do :) can you label the x-axis with the name of the dataset or something? and add a dashed line at p=0.05 for the y-axis.  and make the y scale from 0 to 1 perhaps?}
\cs{Tried again! I deleted the long table in appendix, for now; as the plot and the mean/std are informative enough, I think. Also note that only mcorr and MGC are re-computed for the brain vs noise simulation; others will be updated later.}

\section{Discussion}
\label{conclu}

\paragraph{Summary}
In short, we propose multiscale graph correlation to test independence between data sets, which has been shown to be perform well for testing independence on data of small sample size, high-dimensionality, linearity or nonlinearity. It not only enjoys theoretical guarantee such as being consistent in testing independence, but also exhibits superior numerical performances in a comprehensive simulation setting and real data experiments, comparing to other popular methods. An additional advantage of MGC is that it is readily scalable on big data: existing methods are usually too slow on huge amount of data such that sub-sampling is often necessary; but a loss of testing power may occur depending on the underlying dependency. In comparison, MGC may perform better under sub-sampling; and can use one sub-sample to estimate the optimal scale and another sub-sample for p-value calculation (see appendix section~\ref{appen:eval}).

%The MGC method is also a more scalable and superior approach than existing methods for testing dependency in modern big data with complex dependency. Given a large number of observations, dependence testing may have to be carried out on a sub-sample of the collected data. But existing consistent test statistics like distance correlation may not perform well with small sample size, or would take too much data to achieve good testing power. In comparison, Multiscale graph correlation can utilize two random sub-samples of the same size, one for estimating the optimal scale and another for permutation test. This allows more accurate scale estimation and better performance without losing the speed advantage of sub-sampling. This is also discussed in the Appendix section~\ref{appen:discuss} for the real data experiments in the paper.

\cs{I feel it is not necessary to include next steps in the paper. For example, although the idea to extend two-sample test by local variant is similar to MGC, we shouldn't be too optimistic in this paper before we tried them; also if it does work, probably we don't want to tell others yet :-)}
\jv{good paper writing essentially requires next steps.  it tells people how our work changes the world, what can be achieved next, and in particular, which subset of those things we are planning on doing.}
\cs{I have added sub-sampling, local scale estimation, so on so forth into the next steps. I commented out other next steps that I think is not concrete enough yet; we can add back later. }

\paragraph{Next Steps}
For the future, further investigations on the optimal scale is a worthwhile direction, such as how to more accurately select the local scale under unknown models, and what is the implication of the local scale on the geometry of underlying dependency. Beyond the testing framework, whether MGC and its optimal scale can be applicable to other closely-related areas like dimension reduction and supervised learning, are interesting subjects to follow as well.

%one-sample, two-sample test by the local variants, group testing, anova, regressing out other covariates (local partial correlation), screening, metric spaces.

%different test statistics: there are many possible ways to generate the null distribution, including permutation, but also t-test (as in the mcorr paper \cite{SzekelyRizzo2013a} and the asymptotic distribution derived from \cite{GrettonEtAl2012}), wilcoxon signed rank test, etc..

%scaling up via FlashX?

\section*{Acknowledgment}
\addcontentsline{toc}{section}{Acknowledgment}
This work was partially supported by 
% 
National Security Science and Engineering Faculty Fellowship (NSSEFF), 
% 
Johns Hopkins University Human Language Technology Center of Excellence (JHU HLT COE), 
% 
Defense Advanced Research Projects Agency's (DARPA) SIMPLEX program through SPAWAR contract N66001-15-C-4041, 
% 
and the XDATA program of the Defense Advanced Research Projects Agency (DARPA) administered through Air Force Research Laboratory contract FA8750-12-2-0303.



\appendix
\setcounter{figure}{0}
\renewcommand\thefigure{\arabic{figure}} 


\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{../Figures/Fig2}
\caption{Testing Power Heat map of Local Statistics with respect to Neighborhood Choices for Dimension 1. See figure \ref{figSim2} for details. \jv{fix (1,1) here too please?}
\cs{do you mean the smallest scale should be at the lowest left corner? it is already the case here. }
}
\label{figSim2}
\end{figure}


\section{Functions}
\label{appen:function}

Here the distributions of the $20$ dependencies used in the simulation sections are listed, which are based on a combination of the numerical simulations in \cite{SzekelyRizzoBakirov2007, SimonTibshirani2012, SimonTibshirani2012, GorfineHellerHeller2012} with some adjustments (such as the inclusion of additional noise and an extra weight vector) to better compare all methods in our low and high dimension scenarios.

For the purpose of the increasing dimension scenario, we denote $\mb{x}_{d}$ as the $d$th dimension of $\mb{x}$, and denote $w$ as a size $d_{x} \times 1$ vector with $w_{d}=\frac{1}{d}$. So $w\T \mb{x}$ is a dimension $1$ random variable that is a decaying weighted summation of $\mb{x}=[\mb{x}_{1};\ldots;\mb{x}_{d_{x}}]$; and $w\T \mb{x}$ equals $\mb{x}$ when $d_{x}=1$. In the following, $\mb{u}, \mb{v}$ are auxiliary random variables, $\mc{U}$ denotes the uniform distribution, $\mc{B}$ denotes the Bernoulli distribution, $\mc{N}$ denotes the normal distribution, $c$ is a scalar constant to control the noise level, and $\mb{\epsilon}$ denotes the standard normal distribution for white noise unless mentioned otherwise. The resulting pair of random variables $(\mb{x},\mb{y})$ are used to generate sample data $(X,Y)$ for testing dependency.

\setcounter{equation}{0}
\begin{compactenum}
\item Linear: $\mb{x} \sim \mc{U}(-1,1)^{d_{x}}$, 
\begin{align*}
\mb{y} &=w\T \mb{x}+c\mb{\epsilon}.
\end{align*}
\item Cubic: $\mb{x} \sim \mc{U}(-1,1)^{d_{x}}$, 
\begin{align*}
\mb{y} &=128(w\T \mb{x}-\frac{1}{3})^3+48(w\T \mb{x}-\frac{1}{3})^2-12(w\T \mb{x}-\frac{1}{3})+80c\mb{\epsilon}.
\end{align*}
\item Step Function: $\mb{x} \sim \mc{U}(-1,1)^{d_{x}}$, 
\begin{align*}
\mb{y} &=\mb{I}(w\T \mb{x}>\hat{E}(w\T \mb{x}))+c\mb{\epsilon},
\end{align*}
where $\hat{E}(w\T \mb{x})$ denotes the sample mean of $w\T \mb{x}$ and $\mb{I}$ is the indicator function. 
\item Exponential: $\mb{x} \sim \mc{U}(0,3)^{d_{x}}$, 
\begin{align*}
\mb{y} &=exp(w\T \mb{x})+10c\mb{\epsilon}.
\end{align*}
\item Joint normal: Let $\rho=\frac{1}{2d_{x}}$, $I_{d_{x}}$ as the identity matrix of size $d_{x} \times d_{x}$, $J_{d_{x}}$ as the matrix of ones of size $d_{x} \times d_{x}$, and $\Sigma = \begin{bmatrix} I_{d_{x}}&\rho J_{d_{x}}\\ \rho J_{d_{x}}&I_{d_{x}} \end{bmatrix}$. Then let $(\mb{x},\mb{u}) \sim \mc{N}(0, \Sigma)$, $\mb{\epsilon} \sim \mc{N}(0, I_{d_{x}})$,and $$\mb{y}=\mb{u}+0.5c\mb{\epsilon}.$$ 
\item Quadratic: $\mb{x} \sim \mc{U}(-1,1)^{d_{x}}$,
\begin{align*}
\mb{y}&=(w\T \mb{x})^2+0.5c\mb{\epsilon}.
\end{align*}
\item W Shape: $\mb{x} \sim \mc{U}(-1,1)^{d_{x}}$, $\mb{u} \sim \mc{U}(-1,1)^{d_{x}}$,
\begin{align*}
\mb{y}&=4( ( (w\T \mb{x})^2 - \frac{1}{2} )^2 + w\T \mb{u}/500 )+0.5c\mb{\epsilon}.
\end{align*}
\item Two Parabolas: $\mb{x} \sim \mc{U}(-1,1)^{d_{x}}$, $\mb{\epsilon} \sim \mc{U}(0,1)$, $\mb{u} \sim \mc{B}(0.5)$,
\begin{align*}
\mb{y}&=( (w\T \mb{x})^2  + 2c\mb{\epsilon}) \cdot (\mb{u}-\frac{1}{2}).
\end{align*}
\item Fourth Root: $\mb{x} \sim \mc{U}(-1,1)^{d_{x}}$,
\begin{align*}
\mb{y}&=|w\T \mb{x}|^\frac{1}{4}+\frac{c}{4}\mb{\epsilon}.
\end{align*}
\item Logarithmic: $\mb{x} \sim \mc{N}(0, I_{d_{x}})$, $\mb{\epsilon} \sim \mc{N}(0, I_{d_{x}})$
\begin{align*}
\mb{y}&=log(\mb{x}^2)+3c\mb{\epsilon}.
\end{align*}
\item Circle: $\mb{u} \sim \mc{U}(-1,1)^{d_{x}}$, $\mb{\epsilon} \sim \mc{N}(0, I_{d_{x}})$, $r=1$,
\begin{align*}
\mb{x}_{d}&=r (\sin(\pi \mb{u}_{d+1})  \prod_{j=1}^{d} \cos(\pi \mb{u}_{j})+0.4 \mb{\epsilon}_{d}) \mbox{ for $d=1,\ldots,d_{x}-1$},\\
\mb{x}_{d_{x}}&=r (\prod_{j=1}^{d_{x}} \cos(\pi \mb{u}_{j})+0.4 \mb{\epsilon}_{d_{x}}),\\
\mb{y}&= \sin(\pi \mb{u}_{1}).
\end{align*}
\item Ellipse: Same as above except $r=5$.

\item Spiral: $\mb{u} \sim \mc{U}(0,5)$, $\mb{\epsilon} \sim \mc{N}(0, 1)$, 
\begin{align*}
\mb{x}_{d}&=\mb{u} \sin(\pi \mb{u})  \cos^{d}(\pi \mb{u}) \mbox{ for $d=1,\ldots,d_{x}-1$},\\
\mb{x}_{d_{x}}&=\mb{u} \cos^{d_{x}}(\pi \mb{u}),\\
\mb{y}&= \mb{u} \sin(\pi \mb{u}) +0.4 (d_{x}-1)\mb{\epsilon}.
\end{align*}

\item Square: Let $\mb{u} \sim \mc{U}(-1,1)$, $\mb{u}' \sim \mc{N}(0,1)^{d_{x}}$, $\mb{v} \sim \mc{U}(-1,1)$, $\mb{v}' \sim \mc{N}(0,1)^{d_{x}}$, $\theta=-\frac{\pi}{8}$. Then
\begin{align*}
\mb{x}_{d}&=(\mb{u}+0.02 d_{x}\mb{u}'_{d}) \cos(\theta) + (\mb{v}+0.02 d_{x}\mb{v}'_{d}) \sin(\theta),\\
\mb{y}_{d}&=-(\mb{u}+0.02 d_{x}\mb{u}'_{d}) \sin(\theta) + (\mb{v}+0.02 d_{x}\mb{v}'_{d}) \cos(\theta),
\end{align*}
for $d=1,\ldots,d_{x}$.
\item Diamond: Same as above except $\theta=-\frac{\pi}{4}$.
\item Sine Period 1/2: $\mb{u} \sim \mc{U}(-1,1)$, $\mb{v} \sim \mc{N}(0,1)^{d_{x}}$, $\theta=4\pi$,
\begin{align*}
\mb{x}_{d}&=\mb{u}+0.02 d_{x} \mb{v}_{d} \mbox{ for $d=1,\ldots,d_{x}$}, \\
\mb{y}&=\sin ( \theta \mb{x} )+c\mb{\epsilon}.
\end{align*}
\item Sine Period 1/8: Same as above except $\theta=16\pi$ and the noise is changed to $0.5c\mb{\epsilon}$.
\item Multiplicative Noise: $\mb{x} \sim \mc{N}(0, I_{d_{x}})$, $\mb{u} \sim \mc{N}(0, I_{d_{x}})$, $\mb{\epsilon} \sim \mc{N}(0, I_{d_{x}})$,
\begin{align*}
\mb{y}_{d}&=\mb{u}_{d}\mb{x}_{d}+0.5c\mb{\epsilon}_{d},
\end{align*}
for $d=1,\ldots,d_{x}$.
\item Uncorrelated Binomial: $\mb{x} \sim \mc{B}(0.5)^{d_{x}}$, $\mb{u} \sim \mc{B}(0.5)$,
\begin{align*}
\mb{y}&=(2\mb{u}-1)w\T \mb{x}+0.6c\mb{\epsilon}.
\end{align*}
\item Independent Clouds: Let $\mb{u} \sim \mc{N}(0,I_{d_{x}})$, $\mb{v} \sim \mc{N}(0,I_{d_{x}})$, $\mb{u}' \sim \mc{B}(0.5)^{d_{x}}$, $\mb{v}' \sim \mc{B}(0.5)^{d_{x}}$. Then
\begin{align*}
\mb{x}&=\mb{u}/3+2\mb{u}'-1,\\
\mb{y}&=\mb{v}/3+2\mb{v}'-1.
\end{align*}
\end{compactenum}

\begin{figure}[htbp]
\includegraphics[trim={5cm 0 3.5cm 0},clip, width=1.0\textwidth]{../Figures/Fig0}
\caption{Visualization of 20 dependencies at dimension $1$. The blue points are generated with noise (c=1) for $n=100$ to show the actual sample data in testing, and the red points are generated with no noise for $n=1000$ to highlight each underlying dependency.
}
\label{fig0}
\end{figure}

For each distribution, $\mb{x}$ and $\mb{y}$ are clearly dependent (except type 20); and the sample data $X$ and $Y$ from the above distributions can be easily generated for testing purpose.

The low-dimensional simulation is based on $d_{x}=d_{y}=1$ and $c=1$, with a visualization of all dependencies given in figure~\ref{fig0}. Note that the parameter before $c$ (e.g., there is a $80$ before $c$ in type 2) is a tuned noise parameter for some dependencies, such that the testing power neither increases too fast nor too slow for given distribution: in the absence of noise and at dimension $1$, certain dependency like linear is very easy to be detected so that the testing powers of all methods converge to $1$ at very small $n$, which causes difficulty in comparing the methods; it is also more meaningful to consider noisy scenarios in practice. 

The high-dimensional simulation is based on $c=0$ and increasing $d_{x}$, with $d_{y}=d_{x}$ for type $5,10,14,15,18,20$ and $d_{y}=1$ otherwise. For most dependencies, the decaying vector $w$ is utilized to treat later dimensions as small perturbation, such that the independence testing becomes more difficult as $d_{x}$ increases; but for some complex dependencies like square / diamond / sine period, the testing is already very difficult and $w$ is not used.

\section{Performance Profiles}
\label{appen:profiles}
The performance profiles are drawn by the following steps:

Suppose there are $S$ methods and $T$ different problems, and the respective powers are denoted as $\beta_{\alpha}^{t}(s)$ for $s=1,\ldots,S$ and $t=1,\ldots,T$ at a fixed type 1 error $\alpha$. Then the relative performance for each method is defined as follows:
\begin{align*}
performance_{s}(x) &= \frac{1}{T} \sum_{t=1}^{T} \mb{I}((\beta_{\alpha}^{t}(*)-\beta_{\alpha}^{t}(s)) \leq x)
\end{align*}
where $x \in [0,1]$, $\mb{I}$ is the indicator function, and $\beta_{\alpha}^{t}(*) =\max_{s} \{\beta_{\alpha}^{t}(s)\}$ denotes the best testing power in the $t$th problem. Namely $x$ stands for the difference with respect to the best power, and the relative performance of each method equals the proportion of simulations that the method is worse than the best method by no more than $x$. For example, at $x=0.1$, MGC has a relative performance of $0.75$ if and only if there are $15$ out of $20$ simulations that MGC is worse than the best method by no more than $0.1$ in testing power. 

Note that the performance profiles at $x=0$ stands for the proportion of simulations that the method has the best power; and the curve always increases to $1$ at $x=1$. 

\section{Dependence Measures}
\label{appen:methods}

In this section, we review the Mantel test, distance correlation, modified distance correlation, and the HHG statistic in order. They all start with two Euclidean distance matrices $C=(c_{ij}), D=(d_{ij}) \in \Real^{n \times n}$, where $c_{ij}=\|x_{i}-x_{j}\|_{2}$ and $d_{ij}=\|y_{i}-y_{j}\|_{2}$. 

\subsection{(Global) Distance Correlation}
\label{appen:dcorr}
Given two Euclidean distance matrices $C$ and $D$ for $X$ and $Y$, the sample distance covariance is defined on the doubly centered distance matrices $C^{H}$ and $D^{H}$:
\begin{equation}
\label{dcovEqu}
dcov(X,Y)=\frac{1}{n^2}\sum_{i,j=1}^{n}c^{H}_{ij}d^{H}_{ij},
\end{equation}
where $C^{H}=HCH$, $D^{H}=HDH$ with $H=I_{n}-\frac{J_{n}}{n}$. Then the sample distance variance is defined as
\begin{align*}
dvar(X) &=\frac{1}{n^2}\sum_{i,j=1}^{n}c^{H}_{ij}d^{H}_{ij}\\
dvar(Y) &=\frac{1}{n^2}\sum_{i,j=1}^{n}c^{H}_{ij}d^{H}_{ij},
\end{align*}
and the sample distance correlation follows as
\begin{equation}
\label{dcorrEqu}
dcorr(X,Y)=\frac{dcov(X)}{\sqrt{dvar(X) \cdot dvar(Y)}}.
\end{equation}
In the form of the general correlation coefficient in Equation~\ref{generalCoef}, distance correlation takes $a_{ij}=c^{H}_{ij}$ and $b_{ij}=d^{H}_{ij}$ for all $i,j$.

It is shown in \cite{SzekelyRizzoBakirov2007} that as $n \rightarrow \infty$, $dcorr(X,Y) \rightarrow dcorr(\mb{x},\mb{y}) \geq 0$, where $dcorr(\mb{x},\mb{y})$ denotes the population distance correlation between the random variables $\mb{x}$ and $\mb{y}$. The population distance correlation is defined by the characteristic functions, which is $0$ if and only if $\mb{x}$ and $\mb{y}$ are independent. Thus the sample distance correlation is a consistent test statistic for independence, i.e., the testing power $\beta_{\alpha}(dcorr(X,Y))$ converges to $1$ as $n$ increases, at any fixed type $1$ error level $\alpha$. 

Note that the consistency result assumes finite second moments of $\mb{x}$ and $\mb{y}$, and the consistency holds for a family of metrics including the Euclidean distance \cite{Lyons2013}. Furthermore, all of $dcov, dvar, dcorr$ are always non-negative; and the $dcorr$ defined here is actually the square of distance correlation in \cite{SzekelyRizzoBakirov2007}, but for ease of presentation the square naming is dropped here.

\subsection{(Global) Modified Distance Correlation}
\label{appen:mcorr}
In case of high-dimensional data where the dimension $d_{x}$ or $d_{y}$ increases with the sample size $n$, the distance correlation $dcorr$ may no longer be appropriate. For example, even for independent Gaussian distributions, $dcorr(X,Y) \rightarrow 1$ as $d_{x}, d_{y} \rightarrow \infty$, which may severally impair the testing power of dcorr in high dimension simulations.

To tackle this problem, the modified distance correlation is proposed in \cite{SzekelyRizzo2013a}. The modified distance covariance is defined as
\begin{equation}
\label{mcovEqu}
mcov(X,Y)=\frac{n}{(n-1)^2(n-3)}(\sum_{i \neq j}^{n}c^{M}_{ij}d^{M}_{ij}-\frac{2}{n-2}\sum_{j=1}^{n}c^{M}_{jj}d^{M}_{jj}),
\end{equation}
where $C^{M}$ modifies the entries of $C^{H}$ by
\[c^{M}_{ij} = \left\{
  \begin{array}{lr}
    c^{H}_{ij}-\frac{c_{ij}}{n}, & \mbox{ if } i \neq j \\
    \frac{n\sum_{i}c_{ij}-\sum_{i,j}c_{ij}}{n^2}, &\mbox{ if } i = j 
  \end{array}
\right.
\]
and similarly for $D^{M}$. Then $mvar(X)$ can be defined by replacing all $d^{M}_{ij}$ in Equation~\eqref{mcovEqu} by $c^{M}_{ij}$, similarly for $mvar(Y)$. 

If $mvar(X) \cdot mvar(Y) \leq 0$, the modified distance correlation is set to $0$ (negativity can only occur when $n\leq 2$, equality can only happen in very special cases); otherwise it is defined as
\begin{equation}
\label{mcorrEqu}
mcorr(X,Y)=\frac{mcov(X,Y)}{\sqrt{mvar(X) \cdot mvar(Y)}}.
\end{equation}
In the form of the general correlation coefficient, modified distance correlation takes $a_{ij}=c^{M}_{ij}$ and $b_{ij}=d^{M}_{ij}$ for $i \neq j$, and $a_{jj}=\sqrt{-\frac{2}{n-2}}c^{M}_{jj}$ and $b_{jj}=\sqrt{-\frac{2}{n-2}}d^{M}_{jj}$. %Note that since the diagonals are complex numbers, we will tweak them (without changing its theoretical consistency) when multiscale graph correlation is implemented by mcorr, see in section~\ref{appen:MGC}.

It is shown in \cite{SzekelyRizzo2013a} that $mcorr(X,Y)$ is an unbiased estimator of the population distance correlation $dcorr(\mb{x},\mb{y})$ for all $d_{x}, d_{y}, n$; and mcorr is approximately normal even if $d_{x},d_{y} \rightarrow \infty$. Thus it is also a consistent test statistic for independence, but may work better than dcorr under high-dimension dependencies. 

Note that when there exists repeating points, we usually have $a_{ij} \neq a_{jj}$ for mcorr even if $x_{i}=x_{j}$. In this case, it is necessary to set $a_{ij}=a_{jj}$ for repeating points during global/local mcorr computation, otherwise the diagonal adjustment of mcorr will lose its effect for high-dimensional bias; furthermore, we should tweak the diagonals to $0$ to avoid complex numbers when setting $a_{ij}=a_{jj}$ for repeating points. But the above changes are not necessary when repeating observations do not exist or are already excluded.

\subsection{(Global) Mantel Test}
\label{appen:mantel}
Given two Euclidean distance matrices $C$ and $D$, the Mantel coefficient \cite{Mantel1967} is defined as 
\begin{equation}
Mantel(X,Y)=\frac{\sum_{i \neq j}^{n}(c_{ij}-\hat{E}(C))(d_{ij}-\hat{E}(D))}{\sqrt{\sum_{i \neq j}^{n}(c_{ij}-\hat{E}(C))^2 \sum_{i \neq j}^{n}(d_{ij}-\hat{E}(D))^2}},
\end{equation}
where $\hat{E}(C)=\frac{1}{n(n-1)}\sum_{i \neq j}^{n}(c_{ij})$ and similarly for $\hat{E}(D)$. In terms of the general correlation coefficient in Equation~\ref{generalCoef}, the Mantel coefficient essentially takes $a_{ij}=c_{ij}-\hat{E}(C)$ and $b_{ij}=d_{ij}-\hat{E}(D)$ when $i \neq j$, and $a_{jj}=b_{jj}=0$.

Therefore, the Mantel coefficient treats the two distance matrices as two observation vectors and calculates the Pearson's product-moment correlation coefficient between them. Then the Mantel test is carried out by the permutation test.

Unlike distance correlation and HHG, the Mantel test is not consistent against all dependent alternatives; but it has been a very popular method in biology and ecology due to its simplicity. It is clear from figure~\ref{fig:nD} that the global Mantel coefficient is sub-optimal and appears to be not consistent for many dependencies; but multiscale graph correlation implemented by Mantel nevertheless achieves comparable performances as other variants of MGC, which implies that MGC$\{$Mantel$\}$ may be consistent against most, if not all dependent alternatives.

\subsection{Heller, Heller \& Gorfine (HHG)}
\label{appen:hhg}
Like dcorr and mcorr, the HHG statistic in \cite{HellerGorfine2013} is also distance-based and consistent; and like our multiscale graph correlation, it makes use of the rank information, but in a different manner. It applies Pearson's chi-square test to ranks of distances within each column, and is shown to be better than many global statistics including dcorr under many common nonlinear dependencies in \cite{GorfineHellerHeller2012, HellerGorfine2013}. 

Given the Euclidean distance matrices $C=[c_{ij}]$ and $D=[d_{ij}]$, we denote
\begin{align*}
H_{11}(i,j) &= \sum_{q=1,q\neq i,j}^{n}I(c_{ik} \leq c_{ij})I(d_{ik} \leq d_{ij}) \\
H_{12}(i,j) &= \sum_{q=1,q\neq i,j}^{n}I(c_{ik} \leq c_{ij})I(d_{ik} > d_{ij}) \\
H_{21}(i,j) &= \sum_{q=1,q\neq i,j}^{n}I(c_{ik} > c_{ij})I(d_{ik} \leq d_{ij}) \\
H_{22}(i,j) &= \sum_{q=1,q\neq i,j}^{n}I(c_{ik} > c_{ij})I(d_{ik} > d_{ij}).
\end{align*}
Then the HHG test statistic is
\begin{align*}
HHG(X,Y) &= \sum_{i=1,j\neq i}^{n} \frac{(n-2)(H_{12}(i,j)H_{21}(i,j)-H_{11}(i,j)H_{22}(i,j))^2}{H_{1 \cdot}(i,j)H_{2 \cdot}(i,j)-H_{\cdot 1}(i,j)H_{\cdot 2}(i,j)},
\end{align*}
where $H_{1 \cdot}=H_{11}+H_{12}$, $H_{2 \cdot}=H_{21}+H_{22}$, $H_{\cdot 1}=H_{11}+H_{21}$, and $H_{\cdot 2}=H_{12}+H_{22}$. The permutation test using the HHG statistic is consistent against all dependent alternatives.

It is clear that the HHG statistic is structurally different from dcorr / mcorr / Mantel, and cannot be expressed in terms of the general correlation coefficient in Equation~\ref{generalCoef}. Thus multiscale graph correlation cannot be directly implemented by HHG.

In our numerical simulations, HHG falls a bit short when testing against high-dimensional or close to linear dependencies, but is much more advantageous than other global statistics under many nonlinear dependencies, which makes it a strong competitor in general. 

\section{Multiscale Graph Correlation}
\label{appen:MGC}

For any test statistic that can be expressed by the general correlation coefficient in Equation~\ref{generalCoef}, its multiscale graph correlation can be directly implemented by Equation~\ref{localCoef}. 

Since we take minimal rank among ties, there will be multiple rank $0$ entries in case of repeating data or re-sampling with replacement. Then for Mantel or mcorr it is necessary set $a_{ij}=a_{jj}$ if $x_{i}=x_{j}$; while $a_{jj}=a_{ij}$ already holds when $x_{i}=x_{j}$ for dcorr. As long as $a_{ij}$ is handled properly when $x_{i}=x_{j}$, in practice one can break the ties randomly or use min / average / max ranks without affecting the power of MGC.

Note that in the local family of statistics it suffices to exclude $g_{1l}$ and $g_{k1}$: since $g_{1l}=g_{k1}=g_{11}$, they do not consider any neighbor, merely count the diagonal terms in the distance matrices, and are not meaningful for testing purpose. Therefore they are never considered as optimal scales for MGC.

%As an example, here we show how multiscale graph correlation is implemented by modified distance correlation, as well as explaining some implementation issues.

%By section~\ref{appen:mcorr}, modified distance correlation is equivalent to the general correlation coefficient by taking $a_{ij}=c^{M}_{ij}$ and $b_{ij}=d^{M}_{ij}$ for $i \neq j$, and $a_{jj}=\sqrt{-\frac{2}{n-2}}c^{M}_{jj}$ and $b_{jj}=\sqrt{-\frac{2}{n-2}}d^{M}_{jj}$. %But if multiscale graph correlation by mcorr is implemented directly according to Equation~\ref{localCoef}, $g_{kl}$ may be a complex number when ties occur, e.g., $rank(a_{ij})=0$ and $rank(b_{ij})>0$.

%Note that $a_{jj}$ and $b_{jj}$ converge to $0$, and the expectations of $c^{M}_{jj}$ and $d^{M}_{jj}$ are also $0$. Therefore, instead of using complex number diagonals, we can let $a_{jj}=b_{jj}=0$ with little inferential impact. Then the local variants of modified distance covariance becomes
%\begin{align*}
%mcov_{kl}(X,Y) = \frac{n}{(n-1)^2(n-3)}(\sum_{i \neq j}^{n}c^{M}_{ij}d^{M}_{ij}I(rank(a_{ij})<k))I(rank(b_{ij})<l),
%\end{align*}
%similarly for $mvar_{k}$, and eventually $mcorr_{kl}$ as the local test statistic of mcorr. After the above tweak to the diagonals, MGC$\{$mcorr$\}$ maintains its consistency, has little performance difference from before, and is still superior under high-dimensional dependencies.

%There exists another problem for ties, which is of particular importance for MGC$\{$mcorr$\}$: modified distance correlation improves over the original distance correlation, mostly because its adjustment to the diagonal terms; and if there are repeating points in the data, it is necessary to adjust them in the same manner as the diagonal terms, or mcorr will lose its advantage and not function properly in a permutation test. Although repeating data happen with probability $0$ for data generated by continuous distributions, it can happen for discrete distribution and during resampling.

%The tie problem is handled by taking minimal rank among ties, and let $a_{ij}$ equal $a_{jj}$ whenever $x_{i}=x_{j}$ (or any $x_{i}$ that is rank zero) in Equation~\ref{localCoef2}. This is necessary for any global correlation coefficient that $a_{jj}$ can be different from $a_{ij}$ when $x_{i}=x_{j}$, such as Mantel or mcorr; but does not matter for dcorr, for which $a_{jj}=a_{ij}$ always holds when $x_{i}=x_{j}$. As long as $a_{ij}$ is handled properly when $x_{i}=x_{j}$, in practice one can break the ties randomly or use min / average / max ranks without affecting the power of MGC.

%Last but not least, in the local family of statistics it suffices to exclude $g_{1l}$ and $g_{k1}$: since $g_{1l}=g_{k1}=g_{11}$, they do not consider any neighbor, merely count the diagonal terms in the distance matrices, and are not meaningful for testing purpose. Therefore they should not be considered in general.

\section{Testing Procedure}
\label{appen:tests}

In this section we elaborate on the testing procedure by multiscale graph correlation used in the simulation and the real data experiment. 

Four algorithms are presented in section~\ref{appen:algorithms}: given the choice of any global correlation coefficient, the first algorithm computes all local correlations between two sample data sets; the second algorithm estimates the testing powers of all local statistics based on a given joint distribution, which can be either used to estimate the optimal scale or estimate the MGC power; the third algorithm computes the p-value of the local statistics by a random permutation test; the last algorithm estimates the optimal scale for given data of unknown model based on the permutation test, and outputs the estimated MGC p-value. 

Section~\ref{appen:eval} shows how the algorithms are used to calculate the testing powers of MGC in the simulations and the p-values of MGC in the real data experiment. And section~\ref{appen:diss} offers more detailed discussions regarding the optimal scale estimation of MGC.

\subsection{Algorithms}
\label{appen:algorithms}
The algorithms are implemented in Matlab and R, with the pseudo-code shown in Algorithm~\ref{algLGC},~\ref{algPower},~\ref{algPerm},~\ref{algPerm2}.

The first algorithm is the core of the MGC statistic, which computes all local correlations based on given distance matrices $C$ and $D$. The function calculates Equation~\ref{localCoef} for all scales by efficiently implementing respective matrix manipulations. Note that a priori assumption is a global function that returns $\{a_{ij}\},\{b_{ij}\}$ and the ranks, according to the choice of the global coefficient coefficient.

The second algorithm computes the testing powers of all local statistics by repeated simulating samples generated from the joint distribution $f_{xy}$. Sample data under the null and the alternative area repeatedly generated for $r$ Monte-Carlo replicates, and the first algorithm is applied to estimate the local statistics under the null and the alternative. Then the testing power at any local scale and any type 1 error level can be estimated; and the true optimal scale can be found by maximizing all local testing powers.

The third algorithm computes the p-values of all local statistics by the random permutation test with $r$ random permutations. Once an optimal scale is estimated, the p-value at the optimal scale equals the p-value of MGC.

The fourth algorithm sequentially approximates the optimal scale $(k^{*},l^{*})$ on a given data of unknown model, and outputs the estimated MGC p-value. We first locate some $k^{*}$ or $l^{*}$ whose powers are sufficiently high in the row/column (i.e., most scales along the row/column have significant p-values), then determine the other optimal index by minimizing the p-value on the fixed row/column. Additional verifications are used to avoid the discovery of erroneous scales: if few or no row/column has a sufficiently high power, the optimal scale is left blank and the resulting MGC p-value equals $1$; but if the last row or column has the highest power, we directly take $(n,n)$ as the optimal scale rather than left blank, i.e., MGC equals the global statistic.

The complexity of algorithm~\ref{algLGC} is $O(n^2 \log n)$: the global function takes $O(n^2 \log n)$, and the following loops take $O(n^2)$. Algorithm~\ref{algPower} takes $O(rn^2 \log n)$: it takes $O(rn^2 \log n)$ to generate data and calculate the test statistics, and $O(n^2 (r+\log n))$ to estimate the power. Both algorithm~\ref{algPerm} and algorithm~\ref{algPerm2} take $O(rn^2 \log n)$ as well. 

Note that the first three algorithms can be used for global dcorr / mcorr / Mantel / HHG, by excluding the respective local parts, i.e., in algorithm~\ref{algLGC}, the loops after the global function are not needed for global correlation; in algorithm~\ref{algPower} and algorithm~\ref{algPerm}, the powers and p-values only need to be estimated for one global correlation rather than $n^2$ local statistics. Therefore, for HHG or any correlation involving sorting, the complexity of each algorithm is the same as before but slightly less in actual running time; and for global dcorr / mcorr / Mantel, the complexity of each algorithm becomes $O(n^2), O(rn^2), O(rn^2)$ since sorting is no longer needed.

\begin{algorithm}
\caption{Local Correlations}
\label{algLGC}
\begin{algorithmic}
\Function{LGC}{$C$,$D$,option}  \Comment{option specifies the global correlation in use}
\State initialize an $n \times n$ matrix $corrXY$, and two vectors $varX$ and $varY$ of size $n \times 1$;
\State $[a,b,rkA,rkB]=global(C,D,option)$; \Comment{all outputs are size $n \times n$}
\For{$j=1,\ldots,n$}
\For{$i=1,\ldots,n$}
\State $ra=rkA$; $rb=rkB$;
\If{$ra==0$}
\State $a_{ij}=a_{jj}$; \Comment{adjust entries corresponding to repeating points}
\EndIf
\If{$rb==0$}
\State $b_{ij}=b_{jj}$;
\EndIf
\State $ra=ra+1$; $rb=rb+1$;
\State $corrXY(ra, rb)=corrXY(ra, rb)+a_{ij}b_{ij}$;
\State $varX(ra)=varX(ra)+a_{ij}^2$;
\State $varY(rb)=varY(rb)+b_{ij}^2$;
\EndFor
\EndFor

\For{$j=1,\ldots,n-1$}
\State $corrXY(1, j+1)=corrXY(1, j)+corrXY(1, j+1)$;
\State $corrXY(j+1,1)=corrXY(j+1,1)+corrXY(j+1,1)$;
\State $varX(j+1)=varX(j)+varX(j+1)$;
\State $varY(j+1)=varY(j)+varY(j+1)$;
\EndFor

\For{$j=1,\ldots,n-1$}
\For{$i=1,\ldots,n-1$}
\State $corrXY(i+1,j+1)=corrXY(i+1,j)+corrXY(i,j+1)+corrXY(i+1,j+1)-corrXY(i,j)$;
\EndFor
\EndFor
\State $corrXY=corrXY./\sqrt{(varX) (varY)^{T}}$; \Comment{$./$ means entry-wise division}
\State \Return $corrXY$;
\Comment{the local test statistics $g_{kl}=corrXY(k,l)$ for each $k,l=1,\ldots,n$}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Testing Power Estimation}
\label{algPower}
\begin{algorithmic}
\Function{TestingPowers}{$f_{xy}$,$r$,$\alpha$,option} 
\State initialize two $n \times n \times r$ array $testN$ and $testA$ to store the local test statistics under the null and the alternative, and an $n \times n$ matrix $power$ to store the empirical power of all local tests at type 1 error level $\alpha$;
\For{$m=1,\ldots,r$} 
\State $(X_{1},Y_{1})=generateData(f_{xy},'dependent')$; \Comment{generate dependent samples}
\State $(X_{2},Y_{2})=generateData(f_{xy},'independent')$; \Comment{generate independent samples}
\State $C_{A}=dist(X_{1})$; $D_{A}=dist(Y_{1})$; 
\State $C_{N}=dist(X_{2})$; $D_{N}=dist(Y_{2})$; \Comment{calculate the distance matrices}
\State $testA(:,:,m)=LGC(C_{A},D_{A},option)$; 
\State $testN(:,:,m)=LGC(C_{N},D_{N},option)$;
\EndFor

\For{$j=1,\ldots,n$}
\For{$i=1,\ldots,n$}
\State $testN(i,j,:)=sort(testN(i,j,:),'decreasing')$; 
\State $cut=testN(i,j,ceil(r\alpha))$; \Comment{estimate the critical value at level $\alpha$}
\State $power(i,j)=mean(testA(i,j,:)>cut)$; \Comment{estimate the power}
\EndFor
\EndFor
\State $ind=find(power==max(power))$; \Comment{find the optimal local scale}
\State \Return $power$, $ind$.
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{P-value Estimation}
\label{algPerm}
\begin{algorithmic}
\Function{PermutationTest}{$X$,$Y$,$r$,option}
\State initialize an $n \times n$ matrix $p$ to store the p-values of all local tests;
\State $C=dist(X)$; $D=dist(Y)$; \Comment{calculate the distance matrices}
\State $cut=LGC(C,D,option)$; \Comment{calculate the observed test statistics}
\For{$m=1,\ldots,r$}
\State $per=randperm(n)$; \Comment{generate a random permutation}
\State $cut2=LGC(C,D(per,per),option)$; \Comment{calculate the permuted test statistics}
\For{$j=1,\ldots,n$}
\For{$i=1,\ldots,n$}
\If{$cut2(i,j)<cut(i,j)$}
\State $p(i,j)=p(i,j)+1/r$;
\EndIf
\EndFor
\EndFor
\EndFor
\State \Return $p$.
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{MGC P-value by Optimal Scale Approximation}
\label{algPerm2}
\begin{algorithmic}
\Function{MGCPermutationTest}{$X$,$Y$,$r$,option}
\State $pAll=PermutationTest(X,Y,r,option)$; $n=size(X,1)$;
\State $\alpha=0.05$; \Comment{the level to determine whether a local p-value is significant}
\State $\delta=0.85$; \Comment{the threshold to determine whether a row/column is sufficiently powerful}
\State $\gamma=n/20$; \Comment{the threshold to determine whether there are multiple rows/columns that are powerful}
\State $pRow=mean(pAll(2:end,1:end)<\alpha,1)$; \Comment{the power at each fixed $k$}
\State $pCol=mean(pAll(1:end,2:end)<\alpha,2)$; \Comment{the power at each fixed $l$}
\State $k=find(pRow>\delta)$; $l=find(pCol>\delta)$; 
\If{$length(k)<length(l)$} \Comment{test on the column instead, if there are more powerful columns}
\State $pAll=transpose(pAll)$; $pRow=pCol$; $k=l$; 
\EndIf

\If{$length(k)<\gamma$} 
\State $ind=[]; p1=1$; \Comment{return blank when there are only a few or no indices with high power}
\If{$pRow(n)>\delta$ or $sum(pRow(n)<pRow)==0$}
\State $ind=[n,n]; p1=pAll(ind)$; \Comment{use the largest scale instead when the last index has largest power}
\EndIf
\State \Return $p$;
\EndIf

\State $[k,l]=find(pAll(k,:)==min(pAll(k,:)),1,'last')$; \Comment{find the other index by minimizing the p-values}
\State $ind=[k,l]$; $p=pAll(ind)$; \Comment{use the local p-value at the estimated optimal scale as MGC p-value}
\State \Return $p$.
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Evaluation of MGC}
\label{appen:eval}

To evaluate MGC in simulations or real data, the optimal scale of MGC needs to be estimated first. By running algorithm~\ref{algPower}, it estimates the testing powers $\hat{\beta}_{\alpha}(g_{kl})$ of all local statistics for any known model, so the optimal scale can be estimated by maximizing the testing powers:
\begin{equation}
\label{power}
(k^{*},l^{*})=\arg\max_{k,l \in [2,\ldots,n] }\{\hat{\beta}_{\alpha}(g_{kl})\}.
\end{equation}
If there are more than one optimal neighborhood choices, we pick the scale that maximizes the mean difference of the test statistic under the null and the alternative. Then the testing power of MGC can be quickly determined by running algorithm~\ref{algPower} again to estimate the power at the optimal scale $(k^{*},l^{*})$. 

In case of given observations $(X,Y)$ of unknown distributions, we use algorithm~\ref{algPerm2} to estimate the optimal scale. Without loss of generality, suppose there are more powerful rows than columns, algorithm~\ref{algPerm2} estimates the optimal scale $(k^{*},l^{*})$ by sequentially solving the following two objective functions
\begin{align*}
\label{power}
k_{s}&=\arg_{k \in [2,\ldots,n] } (\sum_{l=2}^{n}\frac{I(p_{kl}<\alpha)}{n-1} > \delta),\\
[k^{*},l^{*}]&=\arg\min_{k \in k_{s}, l \in [2,\ldots,n] } p_{kl},
\end{align*}
where $p_{kl}$ denotes the local p-value at each $(k,l)$, $\alpha$ is the type $1$ error level, and $\delta$ is a power threshold set as $0.85$. When there are too few $k_{s}$ that has power higher than $\delta$, the optimal scale may be fallible and thus not used (MGC p-value is set to $1$), which avoids erroneous scales to be discovered; under the above exception, if the last index $n$ is among the few indices with sufficient high power, or has the highest power among all $k$, $(n,n)$ is used as the optimal scale rather than blank (MGC equals the global test), which usually guarantees the approximate MGC power to be no worse than the global method.

\subsection{Discussions of Optimal Scale Estimation}
\label{appen:diss}
The motivation of algorithm~\ref{algPerm2} is based on observing the heat maps in section~\ref{main3}, i.e., there exists a fixed $k$ or $l$ such that most scales on the fixed row/column are significant and close to optimal. However, as we have used a sequential approach, algorithm~\ref{algPerm2} does not guarantee the optimal scale to be always correctly identified. 

To validate, we compare the true testing power of MGC\{dcorr\} using algorithm~\ref{algPower}, to its estimated power based on algorithm~\ref{algPerm2}. For each type of dependency in the simulation section, we generate $200$ pairs of dependent data. For each pair of data, all local p-values are calculated by $500$ random permutations; then the true MGC p-value is computed using the true optimal scale from the simulation section, and the estimated MGC p-value is computed by algorithm~\ref{algPerm2}. The independence hypothesis is rejected when the p-value is less than $0.05$, and the power equals the percentage of correct rejection. From figure~\ref{figSimPerm}, We observe that the estimated MGC power by algorithm~\ref{algPower} is very close to the true MGC power for most dependency types, and is still significantly better than the global method. 

\cs{it may be better to not show the above paragraph and figure~\ref{figSimPerm} unless the referee asked; because it kinds of weakens our claims in the main paper a little bit. But I am also ok if you think keeping it here makes algorithm 4 more convincing.}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{../Figures/Fig9}
\includegraphics[width=0.8\textwidth]{../Figures/Fig10}
\caption{Comparing estimated MGC power to true MGC, for the dimension $1$ and high dimensional simulations. For the dimension $1$ simulations, $n=60$ and $d=1$; for the high-dimensional simulations, $n=100$ and $d=d_{m}/2$, where $d_{m}$ is the maximum dimension used in figure~\ref{fig:nD} for each type.} 
\label{figSimPerm}
\end{figure}

Instead of algorithm~\ref{algPerm2}, it is tempting to directly find the optimal scale that minimizes all local p-values; or generate random samples based on a given data, and use algorithm~\ref{algPower} instead. But both approaches are biased, and the false positive rate will be higher than the type $1$ error in the absence of dependency. This is because for a given pair of data, a non-optimal scale can happen to have a significant p-value, which may be falsely identified as optimal if we directly minimize all local p-values; and erroneous scales usually still exist after direct re-sampling, so random samples have the same problem. 

To avoid the discovery of erroneous scales, we first determine one optimal index; and the thresholds $\delta$ and $\gamma$ in algorithm~\ref{algPerm2} guarantees there are multiple rows/columns where most scales are significant. Increasing either threshold makes the algorithm more conservative, which may slightly reduce the estimated MGC power; decreasing either threshold makes more scales discoverable, which boosts the estimated MGC power to be closer to the the theoretical true power, at the cost of potentially inflating the false positive rate. Empirically, choosing $\delta \in [0.75,0.95]$ and $\gamma \in [1,n/10]$ are usually good enough for the estimated MGC power to be close to the truth without inflating much the false positive rate.

This problem does not exist, if we know the underlying true model, or has multiple independent pairs of data from the same model. In case of a known model, we already showed in the simulations that the theoretical MGC power can be achieved without any inflation of the false positive rate, once an optimal scale is determined. In case of multiple independent pairs of data, we can find the optimal scale by minimizing the local p-values from one or multiple pairs of data, then use the optimal scale on another pair of data. Take the brain vs disease for example, if we use left brain vs disease to estimate the optimal scale, the right brain vs disease has a MGC p-value of $0.0063$; and the left brain vs disease has a MGC p-value of $0.0179$, if we use the right brain for scale estimation. Both p-values are very close to the respective MGC p-values reported in the main paper using algorithm~\ref{algPerm2}. This alternative approach is not only suitable when additional data are available, but also ideal for huge amount of data sets where sub-sampling is often necessary for data analysis: we can take one or multiple sub-samples for optimal scale estimation, and another sub-sample of equal size for p-value calculation, which achieves the theoretical MGC power without bias.

\section{Proofs}
\label{appen:proofs}
\begin{appThm}
Suppose for given $f_{xy}$ and $\alpha$, $\beta_{\alpha}(g_{nn}) \rightarrow 1$ as $n \rightarrow \infty$ for given $f_{xy}$ and $\alpha$, then $\beta_{\alpha}(g) \rightarrow 1$ as well.

Therefore, multiscale graph correlation is consistent against all dependent alternatives of finite second moments, when it is implemented by distance correlation or modified distance correlation.
\end{appThm}
\begin{proof}
The power of multiscale graph correlation satisfies
\begin{equation}
\beta_{\alpha}(g)=\max_{k,l \in [2,\ldots,n]}\{\beta_{\alpha}(g_{kl})\} \geq \beta_{\alpha}(g_{nn}).
\end{equation}
So if $\beta_{\alpha}(g_{nn}) \rightarrow 1$, it is immediate that $\beta_{\alpha}(g) \rightarrow 1$.

Since dcorr and mcorr are consistent against all alternatives of finite second moments by \cite{SzekelyRizzoBakirov2007, SzekelyRizzo2013a}, clearly their multiscale graph correlations are also consistent.
\end{proof}

\begin{appThm}
Suppose $\mb{y}=c\mb{x}$ for a non-zero scalar $c$. Then for any $n$ and $\alpha$ it always holds that
\begin{equation}
\beta_{\alpha}(g) = \beta_{\alpha}(g_{nn}).
\end{equation}

Thus multiscale graph correlation is equivalent to the global correlation coefficient under linear dependency.
\end{appThm}
\begin{proof}
To show that MGC is no better than its global correlation coefficient, it suffices to show the p-value of $g_{kl}$ is always no less than the p-value of $g_{nn}$ for all $k,l$.

Under linear dependency, for any global correlation coefficient satisfying Equation~\ref{generalCoef}, by Cauchy-Schwarz inequality it follows that
\begin{equation}
1=g_{nn}(X, Y) \geq g_{nn}(X, YQ)
\end{equation}
for any permutation matrix $Q$, for which the equality holds if and only if $X$ is a scalar multiple of $YQ$. It follows that the p-value of $g_{nn}$ is $\frac{|\Omega|}{n!}$, where $|\Omega|$ equals the cardinality of $\Omega=\{Q, X \mbox{ is a scalar multiple of }YQ\} \subset \{\mbox{all possible permutation matrices }Q\}$. Since the identity matrix is an element of $\Omega$, the p-value of $g_{nn}$ is at least $\frac{1}{n!}$.

For any $Q \in \Omega$ and any $k,l$, clearly $g_{kl}(X,Y)=g_{kl}(X,YQ)$. It follows that the p-value of $g_{kl}$ is no less than $\frac{|\Omega|}{n!}$; and there may exist other permutation matrices $Q \notin \Omega$ such that $g_{kl}(X,Y) \leq g_{kl}(X,YQ)$. Thus the p-value of $g_{kl}$ is always bounded below by the p-value of $g_{nn}$.

Therefore for any $k,l$, it holds that $\beta_{\alpha}(g_{kl}) \leq \beta_{\alpha}(g_{nn})$. Since multiscale graph correlation includes the global test statistic and equals the optimal test statistic in the family, it follows that $\beta_{\alpha}(g) = \beta_{\alpha}(g_{nn})$ at any given type $1$ error level $\alpha$.

Note that this theorem holds for MGC based on any of dcorr / mcorr / Mantel.
\end{proof}

\begin{appThm}
There exists $f_{xy}$, $n$ and $\alpha$ such that 
\begin{equation}
\beta_{\alpha}(g) > \beta_{\alpha}(g_{nn}).
\end{equation}

Thus multiscale graph correlation can be better than its global correlation coefficient under certain nonlinear dependency.
\end{appThm}
\begin{proof}
We give a simple discrete example of $f_{xy}$ at $n=7$, such that the p-value of $g_{kl}$ for some $(k,l) \neq (n,n)$ is strictly lower than the p-value of $g_{nn}$. This is equivalent to say the permutation test power $\beta_{\alpha}(g)$ is larger than $\beta_{\alpha}(g_{nn})$ at an appropriate type $1$ error level $\alpha$.

Suppose under the alternative, $f_{xy}$ is distributed as follows:
\begin{align*} 
\mb{x} &\in \{-1,-\frac{2}{3},-\frac{1}{3},0,\frac{1}{3},\frac{2}{3},1\} \mbox{ without replacement}, \\
\mb{y} &= \mb{x}^2,
\end{align*}
which is a discrete version of the quadratic relationship in the simulations.

In this example all possibilities of $C^{M}$ and $D^{M}$ can be considered, and $g_{kl}(X, Y)$ and $\{g_{kl}(X, YQ)\}$ for all permutation matrices $Q$ can be calculated. Take $g_{nn}=mcorr, n=l=7, k=2$ as an example, $g_{nn}(X, Y)=0.0783$, $g_{kl}(X, Y)=0.0583$, and similarly all possible permuted test statistics. It follows that the p-value of $g_{nn}$ is $0.2683$, while the p-value of $g_{kl}$ is $0.1571$. 

Therefore we have an example of $f_{xy}$ and $n$ such that $\beta_{\alpha}(g_{kl}) > \beta_{\alpha}(g_{nn})$ for some $(k,l) \neq (n,n)$: by choosing $\alpha=0.2, n=7$, it follows that $1=\beta_{\alpha}(g_{kl}) > \beta_{\alpha}(g_{nn})=0$ at $(k,l)=(2,7)$. Then $\beta_{\alpha}(g)=\max_{k,l}{\beta_{\alpha}(g_{kl})}=1>\beta_{\alpha}(g_{nn})$, and MGC$\{$mcorr$\}$ is better than the global mcorr.

Note that we can always consider equally spaced sample points (or randomly sampled points) in $[-1,1]$ for $X$, increase $n$ and reach the same conclusion with smaller p-values; but the computation of all possible permuted test statistics becomes much more time-consuming as $n$ increases. Furthermore, the same conclusion holds for MGC based on dcorr or Mantel using the same example.
\end{proof}

\bibliographystyle{alpha}
\bibliography{references}

\end{document}